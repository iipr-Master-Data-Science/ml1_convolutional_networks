{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introducción a las convnets: Clasificando números\n",
    "\n",
    "\n",
    "\n",
    "Vamos a echarle un vistazo a un ejemplo sencillo de una convnet. La utilizaremos para clasificar el dataset MNIST, que es un dataset abierto que contiene números escritos a mano. \n",
    "\n",
    "![Números escritos a mano del dataset MNIST](http://corochann.com/wp-content/uploads/2017/02/mnist_plot.png)\n",
    "\n",
    "Vamos a crear una primera convnet basica. Es una pila de capas `Conv2D` y `MaxPooling2D`. \n",
    "Lo importante es notar que una convnet toma como input tensores de tamaño `(altura_imagen, anchura_imagen, canales_imagen)`. \n",
    "Para ello primero hay que averiguar el tamaño de las imágenes de nuestro dataset. \n",
    "\n",
    "La red debe tener las siguientes capas:\n",
    "\n",
    "- Una capa convolucional (`Conv2D`) con 32 filtros de 3x3 y activación relu. En esta primera capa deberás indicar el tamaño del input (`input_shape`).\n",
    "- Una segunda capa de Max Pooling (`MaxPooling2D`) de 2x2\n",
    "- Una tercera capa convolucional con 64 filtros de 3x3 y activación relu\n",
    "- Una cuarta capa de Max Pooling (`MaxPooling2D`) de 2x2\n",
    "- Una quinta capa convolucional de 64 filtros de 3x3 y activación relu\n",
    "\n",
    "Sabrás que lo has hecho bien cuando el output de `model.summary()` sea:\n",
    "\n",
    "![imagen_output.png](https://github.com/laramaktub/MachineLearningI/blob/master/imagen_output.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), \n",
    "                        activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Puedes ver arriba que la salida de cada capa `Conv2D` y `MaxPooling2D` es un tensor 3D de dimensiones `(altura, anchura, canales)`. La anchura y la altura tienden a diminuir según vamos yendo mas profundo en la red. El número de canales está controlado por el primer argumento que se le pasa a \n",
    "las capas `Conv2D`  (e.j. 32 o 64).\n",
    "\n",
    "El siguiente paso sería darle nuestro ultimo tensor (de dimensiones `(3, 3, 64)`) como entrada a una red densamente conectada. \n",
    "Estos clasificadores procesan vectores, que son 1D,  mientras que nuestra salida es un tensor 3D. \n",
    "Así que primero tendremos que aplanar nuestra salida 3D y convertirla en 1D y después añadir unas cuantas capas densas:\n",
    "\n",
    "- Primero aplana la salida (`flatten()`)\n",
    "- Añade una primera capa de 64 neuronas y activación relu\n",
    "- Añade una última capa de 10 neuronas (tantas como números puedes clasificar) y activación `softmax`\n",
    "\n",
    "Sabrás que lo has hecho bien cuando el `summary` tenga esta pinta:\n",
    "\n",
    "![imagen_output_flat.png](https://github.com/laramaktub/MachineLearningI/blob/master/imagen_output_flat.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=64, activation='relu'))\n",
    "model.add(layers.Dense(units=10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos clasificar 10 categorías, lo que significa que nuestra capa final debe tener 10 nodos y una función de activación `softmax`.  \n",
    "Vamos a ver que pinta tiene nuestra red:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, nuestra salida de dimension `(3, 3, 64)` han sido aplanadas hasta convertirse en vectores de dimensión `(576,)`, antes de entrar en las dos capas densas.\n",
    "\n",
    "Vamos ahora a entrenar nuestra red con las imágenes del dataset MNIST.\n",
    "\n",
    "Leemos a continuación el dataset y lo metemos dentro de vectores: `train_images`, `train_labels`, `test_images`, `test_labels`.\n",
    "\n",
    "Antes de continuar, imprime:\n",
    "\n",
    "- ¿Cual es el tamaño del dataset de training?\n",
    "- ¿Qué pinta tiene el dataset de training?\n",
    "- ¿Qué pinta tienen las etiquetas de training?\n",
    "- Imprime la cuarta imagen del dataset de training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 78s 7us/step\n",
      "El tamaño del dataset de training es: (60000, 28, 28)\n",
      "El tamaño de las etiquetas de training es: (60000,)\n",
      "El tamaño del dataset de test es: (10000, 28, 28)\n",
      "El tamaño de las etiquetas de test es: (10000,)\n",
      "Primeras etiquetas de training: [5 0 4 1 9 2 1 3 1 4]\n",
      "Cuarta imagen del dataset de training:\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  55 148 210 253 253 113  87 148  55   0]\n",
      " [  0   0   0   0   0   0  87 232 252 253 189 210 252 252 253 168   0]\n",
      " [  0   0   0   0   4  57 242 252 190  65   5  12 182 252 253 116   0]\n",
      " [  0   0   0   0  96 252 252 183  14   0   0  92 252 252 225  21   0]\n",
      " [  0   0   0 132 253 252 146  14   0   0   0 215 252 252  79   0   0]\n",
      " [  0   0 126 253 247 176   9   0   0   8  78 245 253 129   0   0   0]\n",
      " [  0  16 232 252 176   0   0   0  36 201 252 252 169  11   0   0   0]\n",
      " [  0  22 252 252  30  22 119 197 241 253 252 251  77   0   0   0   0]\n",
      " [  0  16 231 252 253 252 252 252 226 227 252 231   0   0   0   0   0]\n",
      " [  0   0  55 235 253 217 138  42  24 192 252 143   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  62 255 253 109   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  71 253 252  21   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 253 252  21   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  71 253 252  21   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 106 253 252  21   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  45 255 253  21   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 218 252  56   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  96 252 189  42   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14 184 252 170  11   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  14 147 252  42   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print('El tamaño del dataset de training es: {}'.format(train_images.shape))\n",
    "print('El tamaño de las etiquetas de training es: {}'.format(train_labels.shape))\n",
    "print('El tamaño del dataset de test es: {}'.format(test_images.shape))\n",
    "print('El tamaño de las etiquetas de test es: {}'.format(test_labels.shape))\n",
    "#print(train_images[1])\n",
    "print('Primeras etiquetas de training: {}'.format(train_labels[0:10]))\n",
    "print('Cuarta imagen del dataset de training:')\n",
    "# Le quitamos los bordes para que sea vea bien\n",
    "print(train_images[4, :, 5:22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vas a darle la forma adecuada a los datasets de training y test para poder meterlos a la red neuronal.  \n",
    "Pasa las labels, que ahora mismo son números, a su forma categórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compila el modelo indicando cuales son los datos de entrenamiento y sus etiquetas.  \n",
    "Utilizando el optimizador `rmsprop` y como loss function usa la entropía cruzada categórica.  \n",
    "Entrena después el modelo durante 5 épocas y un tamaño de batch de 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 64s - loss: 0.1738 - acc: 0.9443\n",
      "Epoch 2/5\n",
      " - 59s - loss: 0.0466 - acc: 0.9856\n",
      "Epoch 3/5\n",
      " - 60s - loss: 0.0314 - acc: 0.9904\n",
      "Epoch 4/5\n",
      " - 61s - loss: 0.0242 - acc: 0.9927\n",
      "Epoch 5/5\n",
      " - 54s - loss: 0.0190 - acc: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa26c0947b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'],)\n",
    "model.fit(x=train_images, y=train_labels, batch_size=64, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a evaluar el modelo con las imágenes de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 658us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x=test_images, y=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime la accuracy del test que acabas de realizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con el conjunto de test, las perdidas son 0.029792852709558063, y el accuracy 0.9911\n"
     ]
    }
   ],
   "source": [
    "print('Con el conjunto de test, las perdidas son {0}, y el accuracy {1}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('net_numbers.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el modelo que acabas de guardar (`load`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/virtual-envs/my-test-3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/virtual-envs/my-test-3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model1 = load_model('net_numbers.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una imagen con un número escrito a mano.  \n",
    "Haz una predicción (`predict_classes`) con la imágen del número que acabas de escribir.  \n",
    "Prueba con unos cuantos números... ¿Lo hace bien?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la imagen 0, se ha predicho un 0\n",
      "Para la imagen 1, se ha predicho un 1\n",
      "Para la imagen 2, se ha predicho un 2\n",
      "Para la imagen 3, se ha predicho un 3\n",
      "Para la imagen 4, se ha predicho un 4\n",
      "Para la imagen 5, se ha predicho un 5\n",
      "Para la imagen 6, se ha predicho un 6\n",
      "Para la imagen 7, se ha predicho un 4\n",
      "Para la imagen 8, se ha predicho un 8\n",
      "Para la imagen 9, se ha predicho un 4\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "for i in range(0,10):\n",
    "    img = image.load_img('test_numbers/{}.png'.format(i), target_size=(img_width, img_height), color_mode=\"grayscale\")\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x/255, axis=0)\n",
    "    print('Para la imagen {}, se ha predicho un {}'.format(i, model1.predict_classes(x)[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
